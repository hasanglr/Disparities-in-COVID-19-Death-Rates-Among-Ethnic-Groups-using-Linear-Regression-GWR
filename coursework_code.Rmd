## Disparities in COVID-19 Death Rates Among Ethnic Groups in England and Wales

```{r}

#loading necessary libraries for this project

##importing data and wrangling

library(readxl) #excel file importing
library(sf) #spatial objects
library(here) #the data in the relevant directory
library(tidyverse) #library for modifying columns and adding new ones
library(janitor) #library for rearranging the columns of the dataset
library(units) #library for new units, class and numeric data 
library(reshape2) #library for transforming the data

##data visualisation

library(tmap) #library for plotting and mapping
library(tmaptools) #library for plotting and mapping
library(ggplot2) #library for data visualisation
library(vip) #library for creating feature importance graphs

##data analysis

library(car) #regression
library(broom) #library for tidying statistical models
library(spdep) #library for spatial dependence
library(spgwr) #library for geographically weighted regression
library(spatialreg) #library for spatial lag and error models


```

### 1. Data Importing and Wrangling

#### 1.1. Administrative Spatial Data: Lower Tier Local Authority Boundaries in the UK (2021) and Country Boundaries (2021)

```{r}


#import local authority shapefile


local <- st_read(here::here("data",
                             "Local_Authority_Districts_(December_2021)_GB_BUC",
                             "Local_Authority_Districts_(December_2021)_GB_BUC.shp")) %>%
  
  ##rearrange the column names
  
  clean_names() %>%
  
  ##select local authorities of England and Wales
  
  dplyr::filter(substr(lad21cd, 1, 1) == "E" |  substr(lad21cd, 1, 1) == "W") %>%
  
  ##select only necessary columns (local authority code, name and geometry)

  
  dplyr::select(c("lad21cd", 
                  "lad21nm",
                  "geometry")) %>%
  
  #standardise the la authority column name
  
  rename(la_code = lad21cd)
  


#import Wales boundary

wales <- st_read(here::here("data",
                             "Countries_(December_2021)_UK_BUC",
                             "Countries_(December_2021)_UK_BUC.shp")) %>%
  
  ##rearrange the column names
  
  clean_names() %>%
  
  ##select only Wales
  
  dplyr::filter(ctry21nm =="Wales") %>%
  
  
  ##select only necessary columns

  
  dplyr::select(c("ctry21cd", 
                  "ctry21nm",
                  "geometry"))
  

```

#### 1.2. Dependent Variable: COVID-19 Deaths per 100.000 people in 2022

```{r}

#import covid-19 deaths csv file

covid <-read.csv(here::here("data",
                            "COVID-19 Death Rates",
                            "ltla_2022-12-22.csv"),
                na = " ") %>%
  
  ##rearrange the colum names
  
  clean_names()

#grouping the weekly data to have average deaths per 100.000 in 2022

covid1_group<- covid %>%
  group_by(area_code)%>%
  summarise(deaths_per = mean(cum_ons_deaths_by_registration_date_rate)) %>%
  
  rename(la_code = area_code)
  


```

#### 1.3. Population Data of Ethnic Groups

```{r}


#importing the ethnic population csv data

ethnic <-read_excel(here::here("data",
                               "Ethnic Groups",
                             "datadownload.xlsx"),
                sheet = "Figure 3",
                skip = 4,
                na = " ") %>%
  
  ##rearrange the colum names
  
  clean_names()
  
#grouping ethnic groups into five:asian, black, mixed, white and other ethnic groups

##asian

ethnic$asian = ethnic$asian_asian_british_or_asian_welsh_bangladeshi_percent + ethnic$asian_asian_british_or_asian_welsh_chinese_percent + ethnic$asian_asian_british_or_asian_welsh_indian_percent + ethnic$asian_asian_british_or_asian_welsh_pakistani_percent + ethnic$asian_asian_british_or_asian_welsh_other_asian_percent

##black

ethnic$black = ethnic$black_black_british_black_welsh_caribbean_or_african_african_percent+ ethnic$black_black_british_black_welsh_caribbean_or_african_caribbean_percent + ethnic$black_black_british_black_welsh_caribbean_or_african_other_black_percent

##mixed

ethnic$mixed_multiple = ethnic$mixed_or_multiple_ethnic_groups_other_mixed_or_multiple_ethnic_groups_percent + ethnic$mixed_or_multiple_ethnic_groups_white_and_black_caribbean_percent + ethnic$mixed_or_multiple_ethnic_groups_white_and_asian_percent + ethnic$mixed_or_multiple_ethnic_groups_white_and_black_african_percent

##white
ethnic$white = ethnic$white_english_welsh_scottish_northern_irish_or_british_percent + ethnic$white_irish_percent + ethnic$white_gypsy_or_irish_traveller_percent + ethnic$white_roma_percent + ethnic$white_other_white_percent

##other

ethnic$other = ethnic$other_ethnic_group_any_other_ethnic_group_percent + ethnic$other_ethnic_group_arab_percent

 ethnic <- ethnic %>%
   
 ##selecting necessary columns

 dplyr::select("area_code",
                "area_name",
                "asian",
                "black",
                "mixed_multiple",
                "white",
                "other") %>%
   
   ##rename the local authority code to standardise
   
   rename(la_code = area_code)

```

#### 1.4. Population Density Data

```{r}


#importing the population density csv data

population_den<-read_excel(here::here("data",
                                      "Population Density",
                                      "datadownload2.xlsx"),
                           sheet = "Figure 6",
                           skip = 5,
                           na = " ") %>%
  
  #rearrange the column names
  
  clean_names() %>%
  
  #select necessary columns
  
  dplyr::select("population_density_number_of_usual_residents_per_square_kilometre_2021",
                 "la_code") %>%
  
  #rename the long colum name into mnemonic name
  
  rename(pop_density = population_density_number_of_usual_residents_per_square_kilometre_2021)


```

#### 1.5. Population of people 65 or over

```{r}

#importing the csv data

population_65<-read_excel(here::here("data",
                                     "Population Estimates",
                                     "datadownload3.xlsx"),
                sheet = "Figure 5",
                skip = 5,
                na = " ") %>%
  
  #rearrange the column names
  
  clean_names() %>%
  
  #select necessary columns
  
  dplyr::select("aged_65_years_and_over_percent",
                 "la_code") %>%
  
  #rename the long column into mnemonic name
  
  rename(pop_65over_per = aged_65_years_and_over_percent)


```

#### 1.6. Joining the datasets

```{r}

#left join demographic datasets with local authorities

covid2_local_joined <- local %>%
  
  #join with grouped COVID-19 data, which was weekly before
  
  left_join(., 
            covid1_group, by=c("la_code"="la_code"))%>%
  
  #join with ethnic group data
  
  left_join(., 
            ethnic, by=c("la_code"="la_code"))%>%
  
  # join with population density data
  left_join(., 
          population_den, by=c("la_code"="la_code"))%>%
  
  # join with population of 65 over
  
  left_join(., 
          population_65, by=c("la_code"="la_code"))


```

#### 1.7. Ultimate Dataset for Analysis

```{r}

#exclude missing data before creating spatial weight matrix to use it in spatial autocorrelation and regression models

covid3_analysis <-covid2_local_joined %>%
  
  dplyr::filter(deaths_per != 0)

```

### 2. Data Exploration and Visualisation

#### 2.1. The map of COVID-19 Death Rates in England

```{r}

#mapping the covid-19 death rate across england and wales

tm_shape(covid2_local_joined) +
  
  #choosing COVID-19 Death rates as filling column, map style is natural break
  
  tm_fill("deaths_per",
          style="jenks",
          n= 5, 
          palette = "OrRd",
          title= "Average Deaths per 100.000", 
          labels=c("75 to 145", "146 to 189", "190 to 230", "231 to 275", "276 to 370"))  +
  
  ##local authority boundaries
  
  tm_borders(lwd = 0.1)+
  
  tm_shape(covid3_analysis)+
  
  tm_polygons(alpha=0) +
  
  ##wales boundary
  
  tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  
  ##north arrow
  
  tm_compass(north=0,
             position=c(0.85,0.70),size=1.5, show.labels= 0)+
  
  ##scale bar
  
  tm_scale_bar(position = c(0.67,0.02)) +
  
  ##legend position
  
  tm_layout(legend.position = c(0.02,0.63),
          legend.title.size = 0.7,
          legend.text.size = 0.55) +
  
  ##title
  
   tm_credits("COVID-19 Death Rates Distribution (Natural Breaks)", position=c(0,0.94), size=0.8) 


```

#### 2.2. Spatial Autocorrelation (Global Moran's I) of COVID-19 Deaths

```{r}

#calculate the centroids

centroids<- covid3_analysis%>%
  st_centroid()%>%
  st_geometry()


#find four k-nearest neighbours
knn <-centroids %>%
  knearneigh(., k=4)

knn2 <- knn%>%
  knn2nb()

#calculate the weights

knn3_weight <- knn2 %>%
  nb2listw(., style="W")

#Global Moran's I on COVID-19 Death Rates

moran.test(covid3_analysis$deaths_per, knn3_weight)
```

#### 2.3. Local IndÄ±cators of Spatial Autocorrelation (LISA)

```{r}

#convert the dataset into sp

covid4_analysis_sp <- as_Spatial(covid3_analysis)

#LISA (Local Moran's I) 

local_moran_density <- localmoran(covid4_analysis_sp$deaths_per, knn3_weight)

# rescale COVID-19 death rates

covid4_analysis_sp$deaths_per_scale <- scale(covid4_analysis_sp$deaths_per)

# create a spatial lag variable 

covid4_analysis_sp$deaths_per_lag <- lag.listw(knn3_weight, covid4_analysis_sp$deaths_per)


# convert the sp into sf again

covid5_analysis_sf<- st_as_sf(covid4_analysis_sp)

# set a significance value
sig_level <- 0.1

# classification with significance value
covid5_analysis_sf$quad_sig <- ifelse(covid5_analysis_sf$deaths_per_scale > 0 & 
                                          covid5_analysis_sf$deaths_per_lag > 0 & 
                                          local_moran_density[,5] <= sig_level, 
                                          'High-high (Hot spots)', 
                                   ifelse(covid5_analysis_sf$deaths_per_scale <= 0 & 
                                          covid4_analysis_sp$deaths_per_lag <= 0 & 
                                          local_moran_density[,5] <= sig_level, 
                                          'Low-Low (Cold Spots)', 
                                   ifelse(covid5_analysis_sf$deaths_per_scale > 0 & 
                                          covid5_analysis_sf$deaths_per_lag <= 0 & 
                                          local_moran_density[,5] <= sig_level, 
                                          'High-Low (Outliers)', 
                                   ifelse(covid5_analysis_sf$deaths_per_scale <= 0 & 
                                          covid5_analysis_sf$deaths_per_lag> 0 & 
                                          local_moran_density[,5] <= sig_level, 
                                          'Low-High (Outliers)',
                                   ifelse(local_moran_density[,5] > sig_level, 
                                          'Not-significant', 
                                          'Not-significant')))))


```

Create a dataset including missing local authorities for mapping

```{r}

#convert the sf into data frame

covid6_analysis_df<- as.data.frame(covid5_analysis_sf) %>%
  
  ##select necessary columns
  
    dplyr::select("quad_sig",
                "la_code")

#join 

covid7_mapping_lisa <- covid2_local_joined %>%

  left_join(.,
            covid6_analysis_df, by = c("la_code" = "la_code"))
```

#### 2.4. Mapping Spatial Distribution and Significant Clusters(LISA)

```{r}


#mapping the covid-19 death rate across england

map1_distribution <- tm_shape(covid2_local_joined) +
  
  #choosing COVID-19 Death rates as filling column, map style is natural break
  
  tm_fill("deaths_per",
          style="jenks",
          n= 5, 
          palette = "OrRd",
          title= "Average Deaths per 100.000", 
          labels=c("75 to 145", "146 to 189", "190 to 230", "231 to 275", "276 to 370"))  +
  
  ##local authority boundaries
  
  tm_borders(lwd = 0.1)+
  
  tm_shape(covid3_analysis)+
  
  tm_polygons(alpha=0) +
  
  ##wales boundary
  
  tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  
  ##north arrow
  
  tm_compass(north=0,
             position=c(0.85,0.70),size=1.5, show.labels= 0)+
  
  ##scale bar
  
  tm_scale_bar(position = c(0.67,0.02)) +
  
  ##legend position
  
  tm_layout(legend.position = c(0.02,0.63),
          legend.title.size = 0.7,
          legend.text.size = 0.55) +
  
  ##title
  
   tm_credits("COVID-19 Death Rates Distribution (Natural Breaks)", position=c(0,0.94), size=0.8) 


# map only the statistically significant results here

map2_hotspot <- tm_shape(covid7_mapping_lisa) +
  
  tm_fill(col = 'quad_sig', 
            palette = c("#e34a33", "#bdd7e7", "white",  "#2c7fb8"),
            title= "Clusters") +
  
  tm_borders(lwd = 0.1)+
  
    ##local authority boundaries

tm_shape(covid3_analysis)+
  
  tm_polygons(alpha=0) +
  
    ##wales boundary
  
tm_shape(wales) +
  
  tm_borders(col = "black", lwd=1.6)+
  
  ##north arrow
  
  tm_compass(north=0, position=c(0.85,0.70),size=1.5, show.labels= 0)+
  
  ##scale bar
  
  tm_scale_bar(position = c(0.67,0.02)) +
  
  ##legend position
  
  tm_layout(legend.position = c(0.02,0.63), legend.title.size = 0.7, legend.text.size = 0.55)+
  
  ##title
  
  tm_credits("(b) Significant Clusters (LISA) of COVID-19 Death", position=c(0,0.94), size=0.8) 

figure1=tmap_arrange(map1_distribution, map2_hotspot, ncol=2)


figure1

tmap_save(tm=figure1)


```

#### 2.5. Normality of Variables

```{r}


#create a histogram of dependent variable: COVID-19 Death rates

hist_deaths<- ggplot(covid3_analysis, aes(x=deaths_per)) + 
  geom_histogram(binwidth = 10, color="white",fill="#e34a33", alpha=0.6)+
  geom_vline(data=covid3_analysis, aes(xintercept=mean(deaths_per)),
             linetype="dashed", color="#045a8d")+
  labs(title="a) COVID-19 Deaths",x="Deaths per 100.000 population", y = "Count", size=10)+
  theme_classic()+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))+
  theme(plot.title = element_text(face = "bold"))+
  theme(plot.title = element_text(size = 11))+
  theme(plot.title = element_text(hjust = 0.5))

#create a histogram of the percentage of asian population

hist_asian<- ggplot(covid3_analysis, aes(x=asian)) + 
  
  geom_histogram(binwidth = 2, color="white",fill="#69b3a2", alpha=0.6)+
  geom_vline(data=covid3_analysis, aes(xintercept=mean(asian)),
             linetype="dashed", color="#045a8d")+
  labs(title="d) Asian Population",x="Population Percentage", y = "Count")+
  theme_classic()+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))+
  theme(plot.title = element_text(face = "bold"))+
  theme(plot.title = element_text(size = 11))+
  theme(plot.title = element_text(hjust = 0.5))


#create a histogram of the percentage of black population

hist_black<- ggplot(covid3_analysis, aes(x=black)) + 
  geom_histogram(binwidth = 1, color="white",fill="#E69F00", alpha=0.6)+
  geom_vline(data=covid3_analysis, aes(xintercept=mean(black)),
             linetype="dashed", color="#045a8d")+
  labs(title="e) Black Population",x="Population Percentage", y = "Count")+
  theme_classic()+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))+
  theme(plot.title = element_text(face = "bold"))+
  theme(plot.title = element_text(size = 11))+
  theme(plot.title = element_text(hjust = 0.5))

#create a histogram of the percentage of mixed population

hist_mixed<- ggplot(covid3_analysis, aes(x=mixed_multiple)) + 
  geom_histogram(binwidth = 0.3, color="white",fill="#56B4E9", alpha=0.6)+
  geom_vline(data=covid3_analysis, aes(xintercept=mean(mixed_multiple)),
             linetype="dashed", color="#045a8d")+
  labs(title="f) Mixed Population",x="Population Percentage", y = "Count")+
  theme_classic()+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))+
  theme(plot.title = element_text(face = "bold"))+
  theme(plot.title = element_text(size = 11))+
  theme(plot.title = element_text(hjust = 0.5))

 #create a histogram of the percentage of white population

hist_white<- ggplot(covid3_analysis, aes(x=white)) + 
  geom_histogram(binwidth = 3, color="white",fill="#969696", alpha=0.6)+
  geom_vline(data=covid3_analysis, aes(xintercept=mean(white)),
             linetype="dashed", color="#045a8d")+
  labs(title="g) White Population",x="Population Percentage", y = "Count")+
  theme_classic()+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))+
  theme(plot.title = element_text(face = "bold"))+
  theme(plot.title = element_text(size = 11))+
  theme(plot.title = element_text(hjust = 0.5))

 #create a histogram of the population density

hist_popden<- ggplot(covid3_analysis, aes(x=pop_density)) + 
  geom_histogram(binwidth = 500, color="white",fill="#fc8d59", alpha=0.6)+
  geom_vline(data=covid3_analysis, aes(xintercept=mean(pop_density)),
             linetype="dashed", color="#045a8d")+
  labs(title="c) Population Density",x="Population per kilometer", y = "Count")+
  theme_classic()+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))+
  theme(plot.title = element_text(face = "bold"))+
  theme(plot.title = element_text(size = 11))+
  theme(plot.title = element_text(hjust = 0.5))

 #create a histogram of the percentage of population aged 65 over

hist_pop65<- ggplot(covid3_analysis, aes(x=pop_65over_per)) + 
  geom_histogram(binwidth = 1, color="white",fill="#404080", alpha=0.6)+
  geom_vline(data=covid3_analysis, aes(xintercept=mean(pop_65over_per)),
             linetype="dashed", color="#045a8d")+
  labs(title="b) 65+ Percentage",x="Population Percentage", y = "Count")+
  theme_classic()+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))+
  theme(plot.title = element_text(face = "bold"))+
  theme(plot.title = element_text(size = 11))+
  theme(plot.title = element_text(hjust = 0.5))

 #create a histogram of the other populations

hist_ot<- ggplot(covid3_analysis, aes(x=other)) + 
  geom_histogram(binwidth = 0.6, color="white",fill="#3B47E7", alpha=0.6)+
  geom_vline(data=covid3_analysis, aes(xintercept=mean(other)),
             linetype="dashed", color="#045a8d")+
  labs(title="h) Other Ethnic Groups ",x="Population Percentage", y = "Count")+
  theme_classic()+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))+
  theme(plot.title = element_text(face = "bold"))+
  theme(plot.title = element_text(size = 11))+
  theme(plot.title = element_text(hjust = 0.5))

#plot histograms

histograms <- grid.arrange(hist_deaths,hist_pop65, hist_popden,hist_asian,hist_black, hist_mixed, hist_white, hist_ot,
          ncol = 3, nrow = 3)


```


```{r}


#adding a small number to the local authority where black population percent is zero for log transformation

covid3_analysis$black[covid3_analysis$la_code =="E07000046"] <- 0.1


```

### 2.5.1. Shapiro-Wilk Test for Dependent Variable and Independent Variables

```{r}

#shapiro wilk - covid19 death rates

shapiro.test(covid3_analysis$deaths_per)


```

```{r}

#shapiro wilk - population 65 over


shapiro.test(covid3_analysis$pop_65over_per)


```

```{r}

#shapiro wilk - asian population


shapiro.test(covid3_analysis$asian)


```

```{r}

#shapiro wilk - black population

shapiro.test(covid3_analysis$black)


```

```{r}

#shapiro wilk - white population

shapiro.test(covid3_analysis$white)


```

```{r}

#shapiro wilk - other population

shapiro.test(covid3_analysis$other)


```

```{r}

#shapiro wilk - mixed population


shapiro.test(covid3_analysis$mixed_multiple)


```

```{r}

#shapiro wilk - population density


shapiro.test(covid3_analysis$pop_density)


```

#### 2.6. Correlation Matrix

\*\*Correlation map code was adapted from Geeks for Geeks retrieved from <https://www.geeksforgeeks.org/how-to-create-correlation-heatmap-in-r/>

<https://stackoverflow.com/questions/63459483/customized-correlation-plot-color>

Correlation map is created to understand the correlation between the variable since it can affect our model.

```{r}


#create a data with only numeric variables

covid8_num <- covid3_analysis%>%
  
  #drop geometry column
  
    st_drop_geometry() %>%
  
  #select numeric columns
  
    dplyr::select("deaths_per",
                  "asian",
                  "black",
                  "white",
                  "mixed_multiple",
                  "other",
                  "pop_density",
                  "pop_65over_per") %>%
  
  #rename columns
  
  rename("Covid19 Deaths" = deaths_per,
         "Asian %" = asian,
         "Black %"= black,
         "White %" = white,
         "Mixed %" = mixed_multiple,
         "Other %" =other,
         "Population Density" = pop_density,
         "65+ %" = pop_65over_per)
         

# creating correlation matrix with two decimals
corr_mat <- round(cor(covid8_num ),2)
 
# reduce the size of correlation matrix
melted_corr_mat <- melt(corr_mat)
head(melted_corr_mat)
 
# plotting the correlation matrix
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2,fill=value)) +
geom_tile() +
  geom_text(aes(label = value))+
  labs(x = "", y = "", fill = "Corr", title = "Correlation Matrix") +
  coord_fixed() +
  theme_minimal()+ 
  
  ##rearrange x axis labels not to have overlapped texts
  
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 8, hjust = 1))+
  ##colors
  
  scale_fill_gradientn(
        limits = c(-1,1),

        # color of the matrix
        colours = c("#3e769e","#7ea3bd","#dfe9f0","white","#edcebe","#de8557","#cc6d3b"), 

        # intervals
        values = scales::rescale(c(-1, -0.80, -0.60, -0.3, 0, 0.3, 0.6, 0.80, 1)))



```

#### 2.7. Pearson Correlation Test

```{r}

#pearson correlation test

test <- cor.test(covid8_num$`Covid19 Deaths`, covid8_num$`Mixed %`)
test


```

```{r}

#pearson correlation test

test <- cor.test(covid8_num$`Covid19 Deaths`, covid8_num$`Population Density`)
test

```

#### 2.8. Correlogram

\*\*Correlogram code was adapted from Chapter 9 Geographically Weighted Regression retrieved from <https://gdsl-ul.github.io/san/geographically-weighted-regression.html>

```{r}

##correlogram

cormat <- cor(covid8_num, use="complete.obs", method="pearson")

# significance test
sig1 <- corrplot::cor.mtest(covid8_num, conf.level = .90)

# creta a correlogram
corrplot::corrplot(cormat, type="lower",
                   method = "circle", 
                   order = "original", 
                   tl.cex = 0.7,
                   p.mat = sig1$p, sig.level = .05, 
                   col = viridis::viridis(100, option = "plasma"),
                   diag = FALSE)



```

### 3. Analysis

#### 3.1. Linear Regression

```{r}

#lr model fitting with log transformation on independent variables

lr_model <- lm(covid3_analysis$deaths_per ~ 
     log(covid3_analysis$asian) + log(covid3_analysis$black) + log(covid3_analysis$mixed_multiple) +log(covid3_analysis$white)+ log(covid3_analysis$pop_density) ++ log(covid3_analysis$other)+ log(covid3_analysis$pop_65over_per),data=covid3_analysis)

```

```{r}

#have a look at the summary of lr

summary(lr_model)


```

#### 3.1.1. Variance Inflation Factor -Multicollinearity

The variance inflation factor can be calculated to check for multicollinearity considering possibility of redundancy between the variables.

By utilising the Variance Inflation Factor (VIF) to make sure the independent variables are not correlated with each other and that their VIF is less than 10, you may determine whether there is multicollinearity among the independent variables. If it is greater than 10, the variables must be removed from the model and the regression must be repeated without the removed variables.

```{r}

#vif check

vif(lr_model)

```

#### 3.1.2. Normality of LR Residuals

```{r}

#creating a data frame from lr_model

model_data <- lr_model %>%
  broom::augment(., covid3_analysis)

#creating a spatial data, including LR results

covid10_lr<- model_data %>%
  mutate(model2resids = residuals(lr_model))

```

```{r}

#histogram of residuals of LR

ggplot(covid10_lr, aes(x=model2resids)) + 
  geom_histogram(binwidth = 10, color="white",fill="#e34a33", alpha=0.6)+
  geom_vline(data=covid10_lr, aes(xintercept=mean(model2resids)),
             linetype="dashed", color="#045a8d")+
  labs(title="LR Residuals",x="Residuals", y = "Count", size=10)+
  theme_classic()+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))+
  theme(plot.title = element_text(face = "bold"))+
  theme(plot.title = element_text(size = 11))+
  theme(plot.title = element_text(hjust = 0.5))

```

#### 3.1.3. Shapiro-Wilk test for LR Residuals

```{r}

shapiro.test(covid10_lr$model2resids)


```

#### 3.1.4. Mapping LR residuals

```{r}

#converting datasets, incuding LR results into sf to map residuals

covid10_lr <- st_as_sf(covid10_lr)

#mapping
tm_shape(covid10_lr) +

  tm_fill("model2resids", style = "jenks", midpoint = 0, palette = "-RdBu",title= "Residuals") +
    
  tm_borders(lwd = 0.1)+
  
  ##local authority boundaries
  
tm_shape(covid3_analysis)+
  
  tm_polygons(alpha=0) +
  
  ##wales boundary
  
tm_shape(wales) +
  
  tm_borders(col = "black", lwd=1.6)+
  
  ##north arrow
  
  tm_compass(north=0, position=c(0.85,0.80))+
  
  ##scale bar
  
  tm_scale_bar(position = c("left", "bottom")) +
  
  ##layout,ititle and legend position
  
  tm_layout("The LR Residuals Across England and Wales",frame = FALSE,legend.position = c("left","bottom"), legend.title.size = 0.5, legend.text.size = 0.5)

```

#### 3.1.5. Spatial Autocorrelation of LR Residuals

```{r}

#apply global moran's I

  moran.test(covid10_lr$model2resids, knn3_weight)


```

#### 3.2. Spatial Errors Model

```{r}

#spatial error model

modelSER <- errorsarlm(covid3_analysis$deaths_per ~ 
     log(covid3_analysis$asian) + log(covid3_analysis$black) + log(covid3_analysis$mixed_multiple) +log(covid3_analysis$white)+ log(covid3_analysis$pop_density) ++ log(covid3_analysis$other)+ log(covid3_analysis$pop_65over_per), data=covid3_analysis, knn3_weight, 
  method = "eigen")

#have a look the summary of SEM

summary(modelSER)

```

#### 3.2.1 Spatial Autocorrelation of SE Residuals

```{r}

#create a new dataset for spatial error model results

modelSER_result <- covid3_analysis
  
# extract the residuals

modelSER_result$RESID_SER <- modelSER$residuals

# apply global Moran's I test on redisuals of SEM

moran.test(modelSER_result$RESID_SER, knn3_weight)


```

#### 3.3. Geographically Weighted Regression

```{r}

# insert centroid coordinates into a dataframe

centroids2 <- st_centroid(covid10_lr)

centroids2<- cbind(centroids2, st_coordinates(centroids2))

```

#### 3.3.1 Optimal Bandwidth

```{r}

# finding the bandwidth 

BwG <- gwr.sel(covid3_analysis$deaths_per ~ 
     log(covid3_analysis$asian) + log(covid3_analysis$black) + log(covid3_analysis$mixed_multiple) +log(covid3_analysis$white) +log(covid3_analysis$other) +log(covid3_analysis$pop_density) + log(covid3_analysis$pop_65over_per), data=covid3_analysis, coords = cbind(centroids2$X, centroids2$Y), adapt = TRUE)

# see optimal bandwidth

BwG
```

#### 3.3.2. Fitting GWR

```{r}


# fitting gwr model

gwr.model <- gwr(covid3_analysis$deaths_per ~ 
     log(covid3_analysis$asian) + log(covid3_analysis$black) + log(covid3_analysis$mixed_multiple) +log(covid3_analysis$white) +log(covid3_analysis$other) + log(covid3_analysis$pop_density) + log(covid3_analysis$pop_65over_per), data=covid3_analysis, coords = cbind(centroids2$X, centroids2$Y), adapt=BwG, hatmatrix=TRUE, se.fit=TRUE)


```

```{r}

#look at the results 

gwr.model

# appending GWR results to new data frame

gwr.data <- as.data.frame(gwr.model$SDF)


```

Retrieving coefficients, Local R2 And Standardised Residuals

```{r}

#new data for GWR results

gwr_result <- covid3_analysis

# insert coefficients into our spatial result data

gwr_result$Coefasian <- gwr.data[,"log.covid3_analysis.asian."]
gwr_result$Coefblack <- gwr.data[,"log.covid3_analysis.black."]
gwr_result$Coefmix_multiple <- gwr.data[,"log.covid3_analysis.mixed_multiple."]
gwr_result$Coefwhite <- gwr.data[,"log.covid3_analysis.white."]
gwr_result$Coefother <- gwr.data[,"log.covid3_analysis.other."]

gwr_result$Coefpop_density <- gwr.data[,"log.covid3_analysis.pop_density."]
gwr_result$Coefpop_65over_per <- gwr.data[,"log.covid3_analysis.pop_65over_per."]


# insert standard errors into our spatial result data

gwr_result$SEasian <- gwr.data[,"log.covid3_analysis.asian._se"]
gwr_result$SEblack <- gwr.data[,"log.covid3_analysis.black._se"]
gwr_result$SEmix_multiple <- gwr.data[,"log.covid3_analysis.mixed_multiple._se"]
gwr_result$SEwhite <- gwr.data[,"log.covid3_analysis.white._se"]
gwr_result$SEother <- gwr.data[,"log.covid3_analysis.other._se"]

gwr_result$SEpop_density <- gwr.data[,"log.covid3_analysis.pop_density._se"]
gwr_result$SEpop_65over_per <- gwr.data[,"log.covid3_analysis.pop_65over_per._se"]

# insert localR2 estimates into our spatial result data

gwr_result$localR2 <- gwr.data[,"localR2"]

gwr_result$gwr.e <- gwr.data[,"gwr.e"]

```

Calculate significant increases and reductions in dependent variable by increase in coefficients

```{r}


# t-score statistic

gwr_result$tstat_asian <- gwr_result$Coefasian / gwr_result$SEasian


gwr_result$tstat_black <- gwr_result$Coefblack / gwr_result$SEblack


gwr_result$tstat_mixed_multiple <- gwr_result$Coefmix_multiple / gwr_result$SEmix_multiple


gwr_result$tstat_white <- gwr_result$Coefwhite / gwr_result$SEwhite


gwr_result$tstat_other <- gwr_result$Coefother / gwr_result$SEother


gwr_result$tstat_population_den <- gwr_result$Coefpop_density / gwr_result$SEpop_density


gwr_result$tstat_population_65over_per<- gwr_result$Coefpop_65over_per / gwr_result$SEpop_65over_per


# create significance column with: "Reduction: Significant", "Not Significant", "Increase: Significant" 

gwr_result$significant_asian <- cut(gwr_result$tstat_asian,
    breaks=c(min(gwr_result$tstat_asian), -2, 2, max(gwr_result$tstat_asian)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))


gwr_result$significant_black <- cut(gwr_result$tstat_black,
    breaks=c(min(gwr_result$tstat_black), -2, 2, max(gwr_result$tstat_black)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))

gwr_result$significant_mixed <- cut(gwr_result$tstat_mixed_multiple,
    breaks=c(min(gwr_result$tstat_mixed_multiple), -2, 2, max(gwr_result$tstat_mixed_multiple)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))


gwr_result$significant_white <- cut(gwr_result$tstat_white,
    breaks=c(min(gwr_result$tstat_white), -2, 2, max(gwr_result$tstat_white)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))

gwr_result$significant_other <- cut(gwr_result$tstat_other,
    breaks=c(min(gwr_result$tstat_other), -2, 2, max(gwr_result$tstat_other)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))


gwr_result$significant_population_den <- cut(gwr_result$tstat_population_den,
    breaks=c(min(gwr_result$tstat_population_den), -2, 2, max(gwr_result$tstat_population_den)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))

gwr_result$significant_population_65over <- cut(gwr_result$tstat_population_65over_per,
    breaks=c(min(gwr_result$tstat_population_65over_per), -2, 2, max(gwr_result$tstat_population_65over_per)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))

```

Join spatial data has missing values and GWR results for mapping

```{r}

#first convert into df to use left_join function

gwr_result_df<- as.data.frame(gwr_result)

#join

gwr_result2 <- covid2_local_joined %>%
  left_join(.,
            gwr_result_df, by = c("la_code" = "la_code"))

```

#### 3.3.3. Mapping Local R2 of GWR

```{r}

# map local R2 to evaluate model performance

localR2_map <- tm_shape(gwr_result2) +
  tm_fill("localR2",
          style="jenks",
          n= 5, 
          palette = "YlGnBu",
          title= "R2", 
          labels=c("41% to 55%", "56 to 62%", "63% to 68%", "69% to 74%", "75% to 83%"))+
  
  tm_borders(lwd = 0.1)+
  
tm_shape(covid3_analysis)+
  
  tm_polygons(alpha=0) +
  
tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  
  tm_compass(north=0,
             position=c(0.85,0.70),size=1.5, show.labels= 0)+
  
  tm_scale_bar(position = c(0.67,0.02)) +
  
tm_layout(legend.position = c(0.02,0.63),
          legend.title.size = 0.9,
          legend.text.size = 0.8) +
  
   tm_credits("The Local R2 of GWR Across England and Wales)", position=c(0,0.94), size=1.2) 

localR2_map

```

```{r}

tmap_save(tm = localR2_map)

```

```{r}

moran.test(gwr_result$localR2, knn3_weight)


```

#### 3.3.4. Mapping Local Coefficients of GWR

```{r}

#mapping the local coefficients

tmap_mode("plot")


#asian population local coefficients

tm1 <- tm_shape(gwr_result2) + 
  
  tm_fill("Coefasian", title = " GWR Coefficients", style = "jenks", midpoint = 0, palette = "RdBu") +
    tm_borders(lwd = 0.1)+
tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  tm_layout(frame=FALSE, legend.position = c("left","bottom"),  legend.title.size=0.5,   legend.text.size = 0.4)+
  tm_credits("(a) Asian Population Percentage", position=c(0,0.75), size=1)

#black population local coefficients

tm2 <- tm_shape(gwr_result2) + 
  
  tm_fill("Coefblack", title = "GWR Coefficients", style = "jenks", midpoint = 0, palette = "RdBu") +
      tm_borders(lwd = 0.1)+
tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+

  tm_layout(frame=FALSE, legend.position = c("left","bottom"),  legend.title.size=0.5,   legend.text.size = 0.4)+
  tm_credits("(b) Black Population Percentage", position=c(0,0.75), size=1) +
  
  tm_compass(north=0, position=c(0.85,0.65))

#mixed population local coefficients

tm3 <- tm_shape(gwr_result2) + 
  
  tm_fill("Coefmix_multiple", title = "GWR Coefficients", style = "jenks", midpoint = 0, palette = "RdBu") +
      tm_borders(lwd = 0.1)+
tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  tm_layout(frame=FALSE, legend.position = c("left","bottom"),  legend.title.size=0.5,   legend.text.size = 0.4)+
  tm_credits("(c) Mixed Population Percentage", position=c(0,0.75), size=1)

#white population local coefficients

tm4 <- tm_shape(gwr_result2) + 
  
  tm_fill("Coefwhite", title = "GWR Coefficients", style = "jenks", midpoint = 0, palette = "RdBu") +
      tm_borders(lwd = 0.1)+
tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  tm_layout(frame=FALSE, legend.position = c("left","bottom"),  legend.title.size=0.5,   legend.text.size = 0.4)+
  tm_credits("(d) White Population Percentage", position=c(0,0.75), size=1) +
    tm_scale_bar(position = c("right", "bottom")) 

#other population local coefficients

tm5 <- tm_shape(gwr_result2) + 
  
  tm_fill("Coefother", title = "GWR Coefficients", style = "jenks", midpoint = 0, palette = "RdBu") +
      tm_borders(lwd = 0.1)+
tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  tm_layout(frame=FALSE, legend.position = c("left","bottom"),  legend.title.size=0.5,   legend.text.size = 0.3)+
  tm_credits("(d) Other Ethnic Population Percentage", position=c(0,0.75), size=1) +
    tm_scale_bar(position = c("right", "bottom")) 

#population density local coefficients

tm6 <- tm_shape(gwr_result2) + 
  
  tm_fill("Coefpop_density", title = "GWR Coefficients", style = "jenks", midpoint = 0, palette = "RdBu") +
      tm_borders(lwd = 0.1)+
tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  tm_layout(frame=FALSE, legend.position = c("left","bottom"),  legend.title.size=0.5,   legend.text.size = 0.4)+
  tm_credits("(d) Population Density per km2", position=c(0,0.75), size=1) +
    tm_scale_bar(position = c("right", "bottom")) 

#population 65 over density local coefficients


tm7<- tm_shape(gwr_result2) + 
  
  tm_fill("Coefpop_65over_per", title = "GWR Coefficients", style = "jenks", midpoint = 0, palette = "RdBu") +
      tm_borders(lwd = 0.1)+
tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  tm_layout(frame=FALSE, legend.position = c("left","bottom"),  legend.title.size=0.5,   legend.text.size = 0.4)+
  tm_credits("(d) 65+ Population Percentage", position=c(0,0.75), size=1) +
    tm_scale_bar(position = c("right", "bottom")) 


t=tmap_arrange(tm1, tm2, tm3, tm4, tm5, tm6, tm7, ncol=3)


t

```

#### 3.3.5. Mapping Significance Level of Coefficents

```{r}

#mapping the significance levels of variables

tmap_mode("plot")


# map only the statistically significant results here

map10_asian <-  tm_shape(gwr_result2) + 
  tm_fill("significant_asian", title = "Legend", style = "cat", labels=c("Signi. Reduction", "Not Significant", "Signi. Increase"), palette = c("#e34a33", "white", "#2c7fb8")) +
  tm_shape(covid3_analysis)+
  tm_polygons(alpha=0) +
  
  tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  
  tm_compass(north=0, position=c(0.85,0.85), size=1.5, show.labels= 0)+
  
  tm_scale_bar(position = c(0.60,0.02)) +
  
  tm_layout(legend.position = c(0.02,0.70), legend.title.size = 0.65, legend.text.size = 0.55)+
  
 tm_credits("(a) Asian %", position=c(0,0.93), size=0.8) 



# black population 

map11_black <-  tm_shape(gwr_result2) + 
  tm_fill("significant_black", title = "Legend", style = "cat", labels=c("Signi. Reduction", "Not Significant", "Signi. Increase"), palette = c("#e34a33", "white", "#2c7fb8")) +
  tm_shape(covid3_analysis)+
  tm_polygons(alpha=0) +
  
  tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  
  tm_compass(north=0, position=c(0.85,0.85), size=1.5, show.labels= 0)+
  
  tm_scale_bar(position = c(0.60,0.02)) +
  
  tm_layout(legend.position = c(0.02,0.70), legend.title.size = 0.65, legend.text.size = 0.55)+
  
 tm_credits("(b) Black %", position=c(0,0.93), size=0.8) 


#white population

map12_white <-  tm_shape(gwr_result2) + 
  tm_fill("significant_white", title = "Legend", style = "cat", labels=c("Signi. Reduction", "Not Significant", "Signi. Increase"), palette = c("#e34a33", "white", "#2c7fb8")) +
  tm_shape(covid3_analysis)+
  tm_polygons(alpha=0) +
  
  tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  
  tm_compass(north=0, position=c(0.85,0.85), size=1.5, show.labels= 0)+
  
  tm_scale_bar(position = c(0.60,0.02)) +
  
  tm_layout(legend.position = c(0.02,0.70), legend.title.size = 0.65, legend.text.size = 0.55)+
  
 tm_credits("(c) White %", position=c(0,0.93), size=0.8) 

#mixed population

map13_mixed <-  tm_shape(gwr_result2) + 
  tm_fill("significant_mixed", title = "Legend", style = "cat", labels=c("Signi. Reduction", "Not Significant", "Signi. Increase"), palette = c("#e34a33", "white", "#2c7fb8")) +
  tm_shape(covid3_analysis)+
  tm_polygons(alpha=0) +
  
  tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  
  tm_compass(north=0, position=c(0.85,0.85), size=1.5, show.labels= 0)+
  
  tm_scale_bar(position = c(0.60,0.02)) +
  
  
  tm_layout(legend.position = c(0.02,0.70), legend.title.size = 0.65, legend.text.size = 0.55)+
  
 tm_credits("(d) Mixed or Multiple %", position=c(0,0.93), size=0.8) 


#population density

map14_pop_density <-  tm_shape(gwr_result2) + 
  tm_fill("significant_population_den", title = "Legend", style = "cat", labels=c("Signi. Reduction", "Not Significant", "Signi. Increase"), palette = c("#e34a33", "white", "#2c7fb8")) +
  tm_shape(covid3_analysis)+
  tm_polygons(alpha=0) +
  
  tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  
  tm_compass(north=0, position=c(0.85,0.85), size=1.5, show.labels= 0)+
  
  tm_scale_bar(position = c(0.60,0.002)) +
  
  tm_layout(legend.position = c(0.02,0.70), legend.title.size = 0.65, legend.text.size = 0.55)+
  
 tm_credits("(e) Population Density", position=c(0,0.93), size=0.8) 


#population 65 over

map15_population_65over <-  tm_shape(gwr_result2) + 
  tm_fill("significant_population_65over", title = "Legend", style = "cat", labels=c("Signi. Reduction", "Not Significant", "Signi. Increase"), palette = c("#e34a33", "white", "#2c7fb8")) +
  tm_shape(covid3_analysis)+
  tm_polygons(alpha=0) +
  
  tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
  
  tm_compass(north=0, position=c(0.85,0.85), size=1.5, show.labels= 0)+

  tm_scale_bar(position = c(0.60,0.002)) +
  
  tm_layout(legend.position = c(0.02,0.70), legend.title.size = 0.65, legend.text.size = 0.55)+
  
 tm_credits("(f) Population over 65 %", position=c(0,0.93), size=0.8) 



figure3 <- tmap_arrange(map10_asian,map11_black, map12_white, map13_mixed,map14_pop_density, map15_population_65over, ncol=3)


figure3


tmap_save(tm=figure3)
```

#### 3.3.6. Normality of Standardised Residuals of GWR

```{r}


# histogram of residuals of gwr


ggplot(gwr_result2, aes(x=gwr.e)) + 
  geom_histogram(binwidth = 10, color="white",fill="#e34a33", alpha=0.6)+
  geom_vline(data=gwr_result, aes(xintercept=mean(gwr.e)),
             linetype="dashed", color="#045a8d")+
  labs(title="GWR Standardized Residuals",x="Residuals", y = "Count", size=10)+
  theme_classic()+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))+
  theme(plot.title = element_text(face = "bold"))+
  theme(plot.title = element_text(size = 11))+
  theme(plot.title = element_text(hjust = 0.5))


```

Shapiro-Wilk test for GWR Residuals

```{r}

shapiro.test(gwr_result$gwr.e)


```

#### 3.3.7. Spatial Autocorrelation of Standardised Residuals of GWR

```{r}


#apply global moran's I on residuals of GWR

  moran.test(gwr_result$gwr.e, knn3_weight)


```

#### 3.3.8. Mapping the residuals of GWR

```{r}

tm_shape(gwr_result2) +
  tm_fill("gwr.e", style = "jenks", midpoint = 0, palette = "-RdBu",title= "Residuals") +
tm_compass(north=0, position=c(0.85,0.80))+
    
  tm_borders(lwd = 0.1)+
  
  ##local authority boundaries
  
  tm_shape(covid3_analysis)+
  
  tm_polygons(alpha=0) +
  
  ##wales boundary
  
  tm_shape(wales) +
  tm_borders(col = "black", lwd=1.6)+
tm_scale_bar(position = c("left", "bottom")) +
tm_layout("The LR Residuals Across England and Wales",frame = FALSE,legend.position = c("left","bottom"), legend.title.size = 0.5, legend.text.size = 0.5)



```
